# -*- coding: utf-8 -*-
"""Minería de Datos - Predicción de Precios de Casa - Métricas de Validación.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XR9M4TXYAMCsttuo4sl6GvUc0oEmsylY

# Minería de Datos: Predicción de Precios de Casa

Utilizaremos el conjunto de datos "California Housing", que contiene información sobre diversas características de casas en California y sus precios de venta. Este conjunto de datos es comúnmente utilizado en ejemplos de aprendizaje automático y está disponible en la biblioteca de conjuntos de datos de scikit-learn en Python. Vamos a seguir los pasos para implementar un proyecto de minería que nos permita predecir los precios de las casas

# Paso 1: Preparación de Datos

*   Importamos el conjunto de datos desde scikit-learn.
*   Exploramos la estructura y las características del conjunto de datos.
"""

from sklearn.datasets import fetch_california_housing

import pandas as pd

# Cargo el dataset de California Housing
california_housing = fetch_california_housing()

# california_housing.feature_names

california_housing.target

# Convierto el dataset a un DataFrame de pandas
df = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)

df.head()

# Agregro la columna objetivo
df['MedHouseVal'] = california_housing.target

df.head()

"""# Paso 2: Exploración de Datos

Visualizamos la distribución de los precios de las casas y exploramos las relaciones entre las características y el precio.
"""

# Analizamos las primeras filas del DataFrame (AED)
print(df.head())

# Resumen estadístico de las características numéricas
print(df.describe())

# Alanlizamos info de la metadata del data set
print(df.info())

import matplotlib.pyplot as plt
import seaborn as sns

# Visualizción de la distribución de precios de las casas
plt.figure(figsize=(10, 6))
sns.histplot(df['MedHouseVal'], bins=30, kde=True)
plt.xlabel('Precio ($)')
plt.ylabel('Frecuencia')
plt.title('Distribución de Precios de Casas')
plt.show()

# Visualización de la relación entre características y precio
sns.pairplot(df[['MedHouseVal', 'AveRooms', 'AveBedrms', 'Population']])
plt.show()

"""# Paso 3: Preprocesamiento de Datos

No se requiere mucho preprocesamiento para este conjunto de datos, pero podríamos normalizar las características si es necesario.
"""

from sklearn.preprocessing import StandardScaler

# Normalización de características
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df.drop('MedHouseVal', axis=1))
df_scaled = pd.DataFrame(df_scaled, columns=df.columns[:-1])
df_scaled['MedHouseVal'] = df['MedHouseVal']

"""# Paso 4: Modelado de Datos

Utilizaremos un modelo de regresión lineal para predecir los precios de las casas.
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# División de datos en conjunto de entrenamiento y prueba
X = df_scaled.drop('MedHouseVal', axis=1)
y = df_scaled['MedHouseVal']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entrenamiento del modelo de regresión lineal
model = LinearRegression()
model.fit(X_train, y_train)

"""# Paso 5: Evaluación y Validación de Modelos

Evaluamos el rendimiento del modelo en el conjunto de prueba.
"""

from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_log_error

# Predicciones en el conjunto de prueba
y_pred = model.predict(X_test)

# Evaluación del modelo
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mape = mean_absolute_percentage_error(y_test, y_pred)
#msle = mean_squared_log_error(y_test, y_pred)
print(f'Error cuadrático medio (MSE): {mse}')
print(f'Coeficiente de determinación (R²): {r2}')
print(f'Error absoluto medio (MAE): {mae}')
print(f'Error porcentual absoluto medio (MAPE): {mape}')
#print(f'Error cuadrático medio logarítmico (MSLE): {msle}')

"""# **Interpretación de las Métricas**

**Error Cuadrático Medio (MSE): 0.5559**
¿Qué es?
Es el promedio de los cuadrados de los errores, es decir, la media de las diferencias al cuadrado entre los valores predichos y los valores reales.

¿Cómo se interpreta?

Penaliza más los errores grandes debido al cuadrado.
Mientras más bajo sea el MSE, mejor es el rendimiento del modelo.

No es fácilmente interpretable en términos de la variable de salida porque está en unidades al cuadrado del valor objetivo (en este caso, del precio de la casa).

En este contexto: un MSE de 0.56 indica que el modelo comete errores de predicción que al cuadrado tienen un promedio de 0.56 unidades². Si los precios están normalizados, es un error moderado.

**Coeficiente de determinación (R²): 0.576**
¿Qué es?
Es una medida que indica qué proporción de la varianza en el valor objetivo puede ser explicada por el modelo.

¿Cómo se interpreta?

R² = 1: predicción perfecta.
R² = 0: el modelo no explica nada mejor que el promedio.
R² < 0: el modelo es peor que predecir con el promedio.

En este contexto: un R² de 0.576 significa que el modelo es capaz de explicar aproximadamente el 57.6% de la variabilidad en los precios de las casas. Esto indica un modelo razonablemente bueno, aunque aún con margen de mejora.

**Error Absoluto Medio (MAE): 0.5332**
¿Qué es?
Es el promedio de los errores absolutos entre las predicciones y los valores reales.

¿Cómo se interpreta?

Es fácil de entender porque está en las mismas unidades que la variable de salida.
Menos sensible a valores atípicos que el MSE.

En este contexto: un MAE de 0.53 indica que, en promedio, el modelo se equivoca en 0.53 unidades (de la variable de precio) al predecir.

**Error Porcentual Absoluto Medio (MAPE): 31.95%**
¿Qué es?
Es el promedio del error absoluto expresado como porcentaje del valor real.

¿Cómo se interpreta?

Fácil de entender porque da una idea del error en porcentaje.

MAPE < 10%: excelente modelo
MAPE 10–20%: buen modelo
MAPE 20–50%: modelo razonable
MAPE > 50%: modelo pobre

En este contexto: un MAPE de 31.95% indica que, en promedio, el modelo comete un error del 32% respecto al precio real de la casa. Esto lo ubica como un modelo razonable, aunque puede mejorarse.

# **Conclusión**:
El modelo logra capturar una parte importante de la relación entre las características de las casas y su precio (**desempeño razonable**).

Sin embargo, aún hay margen para mejorar las predicciones, ya que el **error porcentual medio (MAPE)** ronda el 32%, y el **R²** indica que algo más del 40% de la variabilidad todavía no está explicada.

Esto abre la puerta a trabajar en mejoras como la selección de características, el ajuste de hiperparámetros o probar modelos más complejos.

# Paso 6: Ajuste de Hiperparámetros
En este ejemplo, no ajustaremos hiperparámetros, pero podríamos explorar técnicas como la validación cruzada para optimizar el modelo.  **Lo veremos más adelante**

# Paso 7: Interpretación de Resultados
Interpretamos los coeficientes de regresión para entender qué características tienen más impacto en el precio de las casas.
"""

# Coeficientes de regresión
coefficients = pd.DataFrame(model.coef_, index=X.columns, columns=['Coeficiente'])
print(coefficients)

"""**MedInc (Ingreso Medio): 0.852382**
Este coeficiente positivo indica que, manteniendo todas las demás variables constantes, un aumento en el ingreso medio (MedInc) está asociado con un aumento en el precio de las casas. En promedio, por cada unidad de aumento en el ingreso medio, el precio de la casa aumenta en aproximadamente 0.852382 unidades.

**HouseAge (Edad de la Casa): 0.122382**
Este coeficiente positivo sugiere que, manteniendo todas las demás variables constantes, un aumento en la edad de la casa está asociado con un aumento en el precio de las casas. Sin embargo, el efecto es relativamente pequeño.

**AveRooms (Promedio de Habitaciones): -0.305116**
Este coeficiente negativo indica que, manteniendo todas las demás variables constantes, un aumento en el número promedio de habitaciones está asociado con una disminución en el precio de las casas. Este resultado puede parecer contraintuitivo y podría sugerir que el número de habitaciones puede no estar correctamente ajustado en relación con otras variables o que hay una interacción no capturada por el modelo.

**AveBedrms (Promedio de Dormitorios): 0.371132**
Este coeficiente positivo indica que, manteniendo todas las demás variables constantes, un aumento en el número promedio de dormitorios está asociado con un aumento en el precio de las casas. Es decir, un mayor número de dormitorios tiende a incrementar el valor de la propiedad.

**Population (Población): -0.002298**
Este coeficiente muy cercano a cero indica que el efecto de la población en el precio de las casas es muy pequeño y casi insignificante. Es decir, las variaciones en la población no tienen un impacto significativo en el precio de las casas.

**AveOccup (Promedio de Ocupación): -0.036624**
Este coeficiente negativo indica que, manteniendo todas las demás variables constantes, un aumento en el promedio de ocupación de las viviendas está asociado con una disminución en el precio de las casas. Esto podría sugerir que las áreas con mayor densidad de ocupación tienden a tener precios más bajos, posiblemente por razones de congestión o disponibilidad de espacio.

**Latitude (Latitud): -0.896635**
Este coeficiente negativo indica que, manteniendo todas las demás variables constantes, un aumento en la latitud (más al norte) está asociado con una disminución en el precio de las casas. Esto puede reflejar que las casas en ubicaciones más al norte tienden a ser más económicas.

**Longitude (Longitud): -0.868927**
Este coeficiente negativo indica que, manteniendo todas las demás variables constantes, un aumento en la longitud (más al oeste) está asociado con una disminución en el precio de las casas. Esto puede reflejar que las casas en ubicaciones más al oeste tienden a ser más económicas.

# Paso 7: Visualización de los resultados
Podemos visualizar la relación entre las predicciones y los valores reales en el conjunto de prueba.
"""

# Gráfico de dispersión entre predicciones y valores reales
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.xlabel("Valores Reales")
plt.ylabel("Predicciones")
plt.title("Predicciones vs Valores Reales")
plt.show()

"""Si el modelo está bien ajustado, deberíamos ver una buena correlación entre las predicciones y los valores reales. Sin embargo, siempre es útil observar las métricas (como el MSE y el R2 Score) para asegurarse de que el modelo no esté sobreajustado (Overfitting) o subajustado (underfitting)."""